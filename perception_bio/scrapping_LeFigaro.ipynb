{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bouton 'Mon compte' détecté. Articles supplémentaires peuvent être chargés.\n"
     ]
    }
   ],
   "source": [
    "# Définir les en-têtes HTTP pour éviter d'être bloqué\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fonction pour scraper une page de recherche et récupérer les articles\n",
    "def scrape_page(url, session):\n",
    "    all_articles = []  # Liste de tous les articles\n",
    "    seen_articles = set()  # Ensemble pour garder trace des articles déjà ajoutés\n",
    "\n",
    "    try:\n",
    "        # Envoyer une requête HTTP pour obtenir la page\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Trouver tous les articles pour les deux cas\n",
    "            articles = soup.find_all(\"article\", class_=[\"fig-profil fig-profil-mtpd\", \"fig-profil\"])\n",
    "\n",
    "            for article in articles:\n",
    "                # Extraire le titre\n",
    "                title_element = article.find(\"h2\", class_=\"fig-profil-headline\")\n",
    "                title_link = title_element.find(\"a\") if title_element else None\n",
    "                title_text = title_link.get_text(strip=True) if title_link else \"Titre non disponible\"\n",
    "\n",
    "                # Extraire l'URL de l'article\n",
    "                article_url = title_link[\"href\"] if title_link else None\n",
    "\n",
    "                # Extraire la description\n",
    "                description_element = article.find(\"div\", class_=\"fig-profil-chapo\")\n",
    "                description_text = description_element.get_text(strip=True) if description_element else \"Description non disponible\"\n",
    "\n",
    "                # Extraire la date de publication\n",
    "                date_element = article.find(\"li\", class_=\"fig-date-pub\")\n",
    "                time_element = date_element.find(\"time\") if date_element else None\n",
    "                date_text = time_element[\"datetime\"] if time_element else \"Date non disponible\"\n",
    "\n",
    "                # Ajouter l'article à la liste si non déjà vu\n",
    "                if article_url and article_url not in seen_articles:\n",
    "                    all_articles.append({\n",
    "                        \"Titre\": title_text,\n",
    "                        \"Description\": description_text,\n",
    "                        \"URL\": article_url,\n",
    "                        \"Date\": date_text\n",
    "                    })\n",
    "                    seen_articles.add(article_url)\n",
    "\n",
    "            # Gérer le bouton \"Voir plus de résultats\"\n",
    "            more_button = soup.find(\"button\", class_=\"fh-kw__lk fh-kw__lk--more\")\n",
    "            if more_button:\n",
    "                # Simuler un clic pour charger plus de résultats\n",
    "                next_url = more_button.get(\"data-url\")\n",
    "                if next_url:\n",
    "                    print(f\"Bouton 'Voir plus de résultats' détecté. Scraping de {next_url}\")\n",
    "                    all_articles.extend(scrape_page(next_url, session))\n",
    "            \n",
    "            # Gérer le panneau \"Mon compte\" pour charger dynamiquement les articles\n",
    "            login_button = soup.find(\"button\", class_=\"fh-user__login fh-user__login--is-connected\")\n",
    "            if login_button:\n",
    "                print(\"Bouton 'Mon compte' détecté. Articles supplémentaires peuvent être chargés.\")\n",
    "                # Simuler une interaction ou vérifier si plus de contenu s'affiche dynamiquement\n",
    "\n",
    "            return all_articles\n",
    "\n",
    "        else:\n",
    "            print(f\"Erreur HTTP {response.status_code} lors de l'accès à {url}\")\n",
    "            return []\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erreur de requête pour {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# URL de base de la recherche\n",
    "base_url = \"https://recherche.lefigaro.fr/recherche/agriculture%20bio/\"\n",
    "\n",
    "# Initialiser une session HTTP pour gérer les requêtes\n",
    "with requests.Session() as session:\n",
    "    # Scraper la page unique\n",
    "    articles = scrape_page(base_url, session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py:64\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path is not a valid file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m path\n",
      "\u001b[0;31mValueError\u001b[0m: The path is not a valid file: /usr/local/bin/chromedriver",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Initialiser le WebDriver\u001b[39;00m\n\u001b[1;32m     16\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/usr/local/bin/chromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assurez-vous que le chemin est correct\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_page_with_selenium\u001b[39m(base_url):\n\u001b[1;32m     22\u001b[0m     all_articles \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Liste de tous les articles\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py:50\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[1;32m     49\u001b[0m finder \u001b[38;5;241m=\u001b[39m DriverFinder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_browser_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     51\u001b[0m     options\u001b[38;5;241m.\u001b[39mbinary_location \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_browser_path()\n\u001b[1;32m     52\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py:47\u001b[0m, in \u001b[0;36mDriverFinder.get_browser_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_browser_path\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowser_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py:78\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     77\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrowser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Configurer les options Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Mode sans tête\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Évite les problèmes de mémoire partagée\n",
    "\n",
    "# Initialiser le WebDriver\n",
    "service = Service('/usr/local/bin/chromedriver')  # Assurez-vous que le chemin est correct\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "\n",
    "\n",
    "def scrape_page_with_selenium(base_url):\n",
    "    all_articles = []  # Liste de tous les articles\n",
    "    seen_articles = set()  # Ensemble pour éviter les doublons\n",
    "\n",
    "    try:\n",
    "        # Charger la page\n",
    "        driver.get(base_url)\n",
    "\n",
    "        while True:\n",
    "            # Attendre que le bouton \"Voir plus de résultats\" soit présent\n",
    "            try:\n",
    "                more_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"js_startendeless\"))\n",
    "                )\n",
    "                # Scroller jusqu'au bouton pour le rendre visible\n",
    "                ActionChains(driver).move_to_element(more_button).perform()\n",
    "                # Cliquer sur le bouton pour charger plus de résultats\n",
    "                more_button.click()\n",
    "                time.sleep(2)  # Attendre que les articles se chargent\n",
    "            except Exception as e:\n",
    "                print(\"Aucun bouton 'Voir plus de résultats' ou fin des articles.\")\n",
    "                break\n",
    "\n",
    "        # Une fois tous les articles chargés, récupérer le contenu de la page\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        articles = soup.find_all(\"article\", class_=[\"fig-profil fig-profil-mtpd\", \"fig-profil\"])\n",
    "\n",
    "        for article in articles:\n",
    "            # Extraire le titre\n",
    "            title_element = article.find(\"h2\", class_=\"fig-profil-headline\")\n",
    "            title_link = title_element.find(\"a\") if title_element else None\n",
    "            title_text = title_link.get_text(strip=True) if title_link else \"Titre non disponible\"\n",
    "\n",
    "            # Extraire l'URL de l'article\n",
    "            article_url = title_link[\"href\"] if title_link else None\n",
    "\n",
    "            # Extraire la description\n",
    "            description_element = article.find(\"div\", class_=\"fig-profil-chapo\")\n",
    "            description_text = description_element.get_text(strip=True) if description_element else \"Description non disponible\"\n",
    "\n",
    "            # Extraire la date de publication\n",
    "            date_element = article.find(\"li\", class_=\"fig-date-pub\")\n",
    "            time_element = date_element.find(\"time\") if date_element else None\n",
    "            date_text = time_element[\"datetime\"] if time_element else \"Date non disponible\"\n",
    "\n",
    "            # Ajouter l'article à la liste si non déjà vu\n",
    "            if article_url and article_url not in seen_articles:\n",
    "                all_articles.append({\n",
    "                    \"Titre\": title_text,\n",
    "                    \"Description\": description_text,\n",
    "                    \"URL\": article_url,\n",
    "                    \"Date\": date_text\n",
    "                })\n",
    "                seen_articles.add(article_url)\n",
    "\n",
    "        return all_articles\n",
    "\n",
    "    finally:\n",
    "        driver.quit()  # Fermer le navigateur\n",
    "\n",
    "# URL de base de la recherche\n",
    "base_url = \"https://recherche.lefigaro.fr/recherche/agriculture%20bio/\"\n",
    "\n",
    "# Appeler la fonction\n",
    "articles = scrape_page_with_selenium(base_url)\n",
    "\n",
    "# Afficher les résultats\n",
    "for article in articles:\n",
    "    print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
