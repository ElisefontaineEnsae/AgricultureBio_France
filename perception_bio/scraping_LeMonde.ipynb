{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Définir les en-têtes HTTP pour éviter d'être bloqué\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fonction pour scraper une page et récupérer tous les articles\n",
    "def scrape_all_page(url):\n",
    "    all_articles = []  # Liste de tous les articles\n",
    "    seen_articles = set()  # Ensemble pour garder trace des articles déjà ajoutés\n",
    "\n",
    "    try:\n",
    "        # Envoyer une requête HTTP pour obtenir la page\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Trouver tous les articles dans les balises <div class=\"thread\">\n",
    "            articles = soup.find_all(\"div\", class_=\"thread\")\n",
    "            \n",
    "            for article in articles:\n",
    "                # Extraire le titre\n",
    "                title_element = article.find(\"h3\", class_=\"teaser__title\")\n",
    "                title_text = title_element.get_text(strip=True) if title_element else \"Titre non disponible\"\n",
    "                \n",
    "                # Extraire l'URL de l'article\n",
    "                link_element = article.find(\"a\", class_=\"teaser__link\")\n",
    "                article_url = link_element[\"href\"] if link_element else None\n",
    "                if article_url and not article_url.startswith(\"http\"):\n",
    "                    article_url = f\"https://www.lemonde.fr{article_url}\"  # Construire l'URL complète si nécessaire\n",
    "                \n",
    "                # Extraire la description\n",
    "                description_element = article.find(\"p\", class_=\"teaser__desc\")\n",
    "                description_text = description_element.get_text(strip=True) if description_element else \"Description non disponible\"\n",
    "                \n",
    "                # Ajouter l'article à la liste si non déjà vu\n",
    "                if article_url and article_url not in seen_articles:\n",
    "                    all_articles.append([title_text, description_text, article_url])\n",
    "                    seen_articles.add(article_url)\n",
    "\n",
    "            return all_articles\n",
    "\n",
    "        else:\n",
    "            print(f\"Erreur HTTP {response.status_code} lors de l'accès à {url}\")\n",
    "            return []\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erreur de requête pour {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "url = \"https://www.lemonde.fr/economie/\"\n",
    "articles = scrape_all_page(url)\n",
    "for article in articles:\n",
    "    print(f\"Titre : {article[0]}\")\n",
    "    print(f\"Description : {article[1]}\")\n",
    "    print(f\"URL : {article[2]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
